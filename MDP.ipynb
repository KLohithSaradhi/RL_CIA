{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "###################################\n",
    "# First policy:\n",
    "#           DOWN = 0\n",
    "#           RIGHT = 1\n",
    "#           UP = 2\n",
    "#           LEFT = 3\n",
    "# Second Policy\n",
    "#           DownRight = 0\n",
    "#           UpRight = 1\n",
    "#           UpLeft = 2\n",
    "#           DownLeft = 3\n",
    "###################################\n",
    "POLICIES = [[(1, 0), (0, 1), (-1, 0), (0, -1)], \n",
    "            [(1, 1), (-1, 1), (-1, -1), (1, -1)]]\n",
    "\n",
    "OBSTACLE = 1\n",
    "OBSTACLE_REWARD = -10\n",
    "END_REWARD = 100\n",
    "DUMMY = 0.1\n",
    "E_POWER_SCALING = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dist):\n",
    "    wheel = np.cumsum(dist)\n",
    "    return np.argwhere(np.random.random() < wheel)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e020f40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Grid:\n",
    "    def __init__(self, size, density, seed = 1234):\n",
    "        self.size = size\n",
    "        self.GRID = np.zeros((size, size))\n",
    "\n",
    "        self.START = (0,0)\n",
    "        self.END = (size-1, size-1)\n",
    "\n",
    "        self.density = density\n",
    "        self.seed = seed\n",
    "\n",
    "    def check_collision(self, state):\n",
    "        if state[0] < 0 or state[0] >= self.size or state[1] < 0  or state[1] >= self.size:\n",
    "            return False\n",
    "        elif self.GRID[state[0]][state[1]] == OBSTACLE:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def generate_obstacles(self):\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        RANDOM_MATRIX = np.random.random((self.size, self.size))\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if (i,j) == self.START or (i,j) == self.END:\n",
    "                    continue\n",
    "                if RANDOM_MATRIX[i][j] <= self.density:\n",
    "                    self.GRID[i][j] = OBSTACLE\n",
    "\n",
    "    \n",
    "    def reward(self, state):\n",
    "        if state == self.END:\n",
    "            return END_REWARD\n",
    "        else:\n",
    "            if self.check_collision(state):\n",
    "                #return - np.sqrt(((state[0] - self.END[0])**2 + (state[1] - self.END[1])**2)/ (self.END[0]**2 + self.END[1]**2)) * 5\n",
    "                return -1\n",
    "                #return 0\n",
    "            else:\n",
    "                return OBSTACLE_REWARD\n",
    "            \n",
    "    def display(self):\n",
    "        plt.imshow(1-self.GRID, cmap=\"gray\")\n",
    "            \n",
    "# REWARD DISPLAY\n",
    "temp_env = Grid(10, 0.1, 12345)\n",
    "temp_env.generate_obstacles()\n",
    "reward_grid = np.array([[temp_env.reward((i,j)) for j in range(temp_env.size)] for i in range(temp_env.size)])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "temp_env.display()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reward_grid / 5, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, env, gamma, ACTIONS):\n",
    "        self.env = env\n",
    "        self.num_states = self.env.size * self.env.size\n",
    "        self.gamma = gamma\n",
    "        self.ACTIONS = ACTIONS\n",
    "        self.num_actions = len(self.ACTIONS)\n",
    "        \n",
    "        # q_pi and v_pi\n",
    "        self.q_pi = np.ones((self.num_states, self.num_actions)).astype(np.float32)\n",
    "        self.v_pi = np.full((self.num_states), DUMMY).astype(np.float32)\n",
    "        self.q_pi_prob = self.q_pi / np.sum(self.q_pi, axis = 1).reshape((-1,1))\n",
    "\n",
    "\n",
    "    def update_probs(self):\n",
    "        # self.q_pi_prob = (self.q_pi - np.min(self.q_pi)) / (np.max(self.q_pi, axis = 1) - np.min(self.q_pi, axis = 1))\n",
    "        self.q_pi_prob = np.exp(E_POWER_SCALING * self.q_pi) / np.sum(np.exp(E_POWER_SCALING * self.q_pi), axis = 1).reshape(-1,1)\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, env, POLICIES, gamma = 0.8, exploitation_threshold = 0.3):\n",
    "        self.env = env\n",
    "        self.POLICIES = [Policy(self.env, gamma, p) for p in POLICIES]\n",
    "        self.gamma = gamma\n",
    "        self.exploitation_threshold = exploitation_threshold\n",
    "\n",
    "    def run_episode(self, state):\n",
    "\n",
    "        #print(state, end = \"===>\")\n",
    "        # end condition of recursion\n",
    "        # if self.env.GRID[state[0]][state[1]] == OBSTACLE or state == self.env.END:\n",
    "        #     return self.env.reward(state)\n",
    "        \n",
    "        # default run\n",
    "        \n",
    "        #PICK POLICY\n",
    "        state_index = state[0] * self.env.size + state[1]\n",
    "        state_values = [p.v_pi[state_index] for p in self.POLICIES]\n",
    "        state_values = np.array(state_values)\n",
    "        # state_values = (state_values - np.min(state_values)) / (np.max(state_values) - np.min(state_values + 1e-7))\n",
    "        state_values = np.exp(E_POWER_SCALING * state_values) / np.sum(np.exp(E_POWER_SCALING * state_values))\n",
    "\n",
    "        if np.random.random() < self.exploitation_threshold:\n",
    "            policy_index = np.argmax(state_values)\n",
    "            policy = self.POLICIES[policy_index]\n",
    "            action_index = np.argmax(policy.q_pi_prob[state_index])\n",
    "        else:\n",
    "            policy_index = sample(state_values)\n",
    "            policy = self.POLICIES[policy_index]\n",
    "            action_index = sample(policy.q_pi_prob[state_index])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # perform action\n",
    "        next_state = (state[0] + policy.ACTIONS[action_index][0], state[1] + policy.ACTIONS[action_index][1])\n",
    "        next_state_index = next_state[0] * self.env.size + next_state[1]\n",
    "        #print(next_state)\n",
    "        next_reward = self.env.reward(next_state)\n",
    "\n",
    "        if next_reward == OBSTACLE_REWARD or next_reward == END_REWARD:\n",
    "            #print(\"here\")\n",
    "            G_t = next_reward\n",
    "        else:\n",
    "            G_t = (next_reward + self.gamma * self.run_episode(next_state))\n",
    "\n",
    "        #print(policy.q_pi[state_index], state)\n",
    "        policy.v_pi[state_index] = policy.q_pi_prob[state_index][action_index] * G_t\n",
    "        policy.q_pi[state_index][action_index] = G_t\n",
    "        #print(policy.q_pi[state_index], state)\n",
    "\n",
    "        return G_t \n",
    "    \n",
    "    def infer(self, state):\n",
    "\n",
    "        print(state, end = \"===>\")\n",
    "\n",
    "        # end condition of recursion\n",
    "        if self.env.GRID[state[0]][state[1]] == OBSTACLE or state == self.env.END:\n",
    "            return self.env.reward(state)\n",
    "        \n",
    "        # default run\n",
    "        \n",
    "        #PICK POLICY\n",
    "        state_index = state[0] * self.env.size + state[1]\n",
    "        state_values = [p.v_pi[state_index] for p in self.POLICIES]\n",
    "        state_values = np.array(state_values) / np.sum(state_values)\n",
    "\n",
    "        policy_index = np.argmax(state_values)\n",
    "        policy = self.POLICIES[policy_index]\n",
    "\n",
    "        #picking action\n",
    "        action_index = np.argmax(policy.q_pi_prob[state_index])\n",
    "\n",
    "        # perform action\n",
    "        next_state = (state[0] + policy.ACTIONS[action_index][0], state[1] + policy.ACTIONS[action_index][1])\n",
    "        next_state_index = next_state[0] * self.env.size + next_state[1]\n",
    "        print(next_state)\n",
    "        G_t = self.env.reward(next_state) + self.gamma * self.infer(next_state)\n",
    "\n",
    "        # policy.v_pi[state_index] = G_t\n",
    "        # policy.q_pi[state_index][action_index] = G_t\n",
    "\n",
    "        return G_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_agent = Agent(temp_env, POLICIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9574/10000000 [00:03<53:22, 3119.85it/s]  \n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000000\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#print(\"_______EPISODE________\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     run_reward \u001b[38;5;241m=\u001b[39m \u001b[43mdummy_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     dummy_agent\u001b[38;5;241m.\u001b[39mPOLICIES[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate_probs()\n\u001b[1;32m      5\u001b[0m     dummy_agent\u001b[38;5;241m.\u001b[39mPOLICIES[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate_probs()\n",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     64\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m next_reward\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m (next_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(policy.q_pi[state_index], state)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m policy\u001b[38;5;241m.\u001b[39mv_pi[state_index] \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mq_pi_prob[state_index][action_index] \u001b[38;5;241m*\u001b[39m G_t\n",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     64\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m next_reward\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m (next_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(policy.q_pi[state_index], state)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m policy\u001b[38;5;241m.\u001b[39mv_pi[state_index] \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mq_pi_prob[state_index][action_index] \u001b[38;5;241m*\u001b[39m G_t\n",
      "    \u001b[0;31m[... skipping similar frames: Agent.run_episode at line 66 (2960 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     64\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m next_reward\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     G_t \u001b[38;5;241m=\u001b[39m (next_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(policy.q_pi[state_index], state)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m policy\u001b[38;5;241m.\u001b[39mv_pi[state_index] \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mq_pi_prob[state_index][action_index] \u001b[38;5;241m*\u001b[39m G_t\n",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     47\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(policy\u001b[38;5;241m.\u001b[39mq_pi_prob[state_index])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     policy_index \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPOLICIES[policy_index]\n\u001b[1;32m     51\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m sample(policy\u001b[38;5;241m.\u001b[39mq_pi_prob[state_index])\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36msample\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(dist):\n\u001b[1;32m      2\u001b[0m     wheel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(dist)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwheel\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/numpy/core/numeric.py:625\u001b[0m, in \u001b[0;36margwhere\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;66;03m# then remove the added dimension\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argwhere(a)[:,:\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transpose(\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1984\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nonzero_dispatcher)\n\u001b[1;32m   1893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnonzero\u001b[39m(a):\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;124;03m    Return the indices of the elements that are non-zero.\u001b[39;00m\n\u001b[1;32m   1896\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \n\u001b[1;32m   1983\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnonzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10000000)):\n",
    "    #print(\"_______EPISODE________\")\n",
    "    run_reward = dummy_agent.run_episode(temp_env.START)\n",
    "    dummy_agent.POLICIES[0].update_probs()\n",
    "    dummy_agent.POLICIES[1].update_probs()\n",
    "    if dummy_agent.exploitation_threshold < 0.9:\n",
    "        dummy_agent.exploitation_threshold += 0.00001\n",
    "    # print(\"run-reward : \", run_reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_agent.infer(temp_env.START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c471d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dummy_agent.POLICIES[0].v_pi.reshape((10,10)), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dummy_agent.POLICIES[1].v_pi.reshape((10,10)), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_agent.POLICIES[1].q_pi_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.array([0.5, 0.2, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [sample(dist) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(samples, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dumy:\n",
    "    def __init__(self):\n",
    "        self.x = 10\n",
    "\n",
    "class Big:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.temp = [Dumy(), Dumy()]\n",
    "\n",
    "    def boom(self):\n",
    "        self.temp[0].x = 234\n",
    "\n",
    "        doom = self.temp[1]\n",
    "\n",
    "        doom.x = 13243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Big()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.temp[0].x, obj.temp[1].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.boom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
